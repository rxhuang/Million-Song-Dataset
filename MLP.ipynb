{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOD66Fq57TxT",
        "outputId": "29f23793-2e23-462b-ec23-08597196b44d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byj7GBmC7XJU"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5H-pK-9OeaP"
      },
      "source": [
        "data_p = pd.read_pickle(r'drive/MyDrive/pos')\n",
        "data_n = pd.read_pickle(r'drive/MyDrive/neg')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkOFgXzaPXAx"
      },
      "source": [
        "label0 = np.zeros(len(data_n))\n",
        "label1 = np.ones(len(data_p))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mzb4WGFPXWj"
      },
      "source": [
        "data_features = np.concatenate((data_p, data_n),axis = 0)\n",
        "data_labels = np.concatenate((label1, label0),axis = 0)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zT0EPr8EKW_O",
        "outputId": "b94065d1-81b1-46dc-c28f-0aae4e903876"
      },
      "source": [
        "data_features = np.array(data_features, dtype=np.float)\n",
        "data_labels = np.array(data_labels, dtype=np.long)\n",
        "data_features.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(533692, 562)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DPQbD74TvfV"
      },
      "source": [
        "np.random.seed(10605)\n",
        "np.random.shuffle(data_features) \n",
        "np.random.seed(10605)\n",
        "np.random.shuffle(data_labels)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9opJZB4fhhg",
        "outputId": "50936cd3-ad17-4c0f-880a-8b96e4253ca4"
      },
      "source": [
        "np.sum(data_labels)/len(data_labels)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5621069830538963"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EPF3FMuzhg_",
        "outputId": "fc5e9f45-39f3-45a2-e0ed-1e8b7bc0c8c5"
      },
      "source": [
        "data_labels"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, ..., 1, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHJwH-LNfhj9"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_G7_4lJGsTl"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "train_x = data_features[30000:]\n",
        "train_y = data_labels[30000:]\n",
        "test_x = data_features[:30000]\n",
        "test_y = data_labels[:30000]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wa1LeqESZKeF",
        "outputId": "de9f830a-3286-4d5f-9617-88d354b003ef"
      },
      "source": [
        "test_x.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30000, 562)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_-WtEwuH_Pf",
        "outputId": "a78ffcbc-228c-4cc0-d1d7-f1299b6d1879"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0T5MuFPHP4L"
      },
      "source": [
        "class SongDataset(Dataset):\n",
        "    def __init__(self, x, y=None):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx], self.y[idx]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEL7se8uH3gy"
      },
      "source": [
        "def get_dataloader(trainset, valset = None, batch_size = 256, num_workers = 4):\n",
        "    train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers,drop_last = True)\n",
        "    \n",
        "    if(valset is None):\n",
        "        val_loader = None\n",
        "    else:\n",
        "        val_loader = DataLoader(valset, batch_size=batch_size, shuffle=False, num_workers=num_workers,drop_last = True)\n",
        "        \n",
        "    return (train_loader, val_loader)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuZMt4P0H93I"
      },
      "source": [
        "trainset = SongDataset(train_x,train_y)\n",
        "valset = SongDataset(test_x,test_y)\n",
        "train_loader, val_loader = get_dataloader(trainset,valset)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErxGZF7DIDNQ"
      },
      "source": [
        "def train_one_epoch(model, train_loader, optimizer):\n",
        "    \n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "    acc = 0\n",
        "    \n",
        "    for x, y in train_loader:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        y_hat = model(x.float())\n",
        "        loss = criterion(np.squeeze(y_hat), y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        #compute loss and accuracy \n",
        "        count += 1\n",
        "        total_loss += loss.item()\n",
        "        values, indices = y_hat.max(1)\n",
        "        acc += (y-indices == 0).sum(dim=0).item()\n",
        "    \n",
        "    return(total_loss/count, acc/len(train_loader.dataset))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xES04K_3IOP0"
      },
      "source": [
        "model = nn.Sequential(\n",
        "            nn.Linear(562, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.Linear(1024, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(2048),\n",
        "            nn.Linear(2048, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(4096),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(4096),\n",
        "            nn.Linear(4096, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(2048),\n",
        "            nn.Linear(2048, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.Linear(64, 2)\n",
        "        )\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-YZx31OI8h0",
        "outputId": "46b9c5a8-904f-405e-aef5-9ec863d212a6"
      },
      "source": [
        "for i in range(10):\n",
        "  avg_train_loss, train_accuracy = train_one_epoch(model, train_loader, optimizer)\n",
        "  print(train_accuracy)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.849261056359839\n",
            "0.9620700745693797\n",
            "0.9800929933371981\n",
            "0.9865850559468882\n",
            "0.9888940066548605\n",
            "0.991258546889766\n",
            "0.9918779730470207\n",
            "0.9919554013166777\n",
            "0.9933649928924819\n",
            "0.9937044860748235\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvswkFN2MMHd"
      },
      "source": [
        "def validate_model(model, val_loader):  \n",
        "    \"\"\"\n",
        "    Validate a given model with a validation dataloader.\n",
        "    \n",
        "    args:\n",
        "        model (nn.Module): the trained model \n",
        "        val_loader (DataLoader): iterable for valset minibatches\n",
        "\n",
        "    return: Tuple(avg_val_loss, val_accuracy, val_time)\n",
        "        avg_val_loss (float): average validation loss across batches\n",
        "        val_accuracy (float): portion of correctly classified images in the validation dataset\n",
        "        val_time (float): the time taken to run this function\n",
        "    \"\"\"\n",
        "    \n",
        "    model.eval()\n",
        "    torch.no_grad()\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "    acc = 0\n",
        "    \n",
        "    for x, y in val_loader:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        y_hat = model(x.float())\n",
        "        loss = criterion(y_hat, y)\n",
        "        \n",
        "        #compute loss and accuracy \n",
        "        count += 1\n",
        "        total_loss += loss.item()\n",
        "        values, indices = y_hat.max(1)\n",
        "        acc += (y-indices == 0).sum(dim=0).item()\n",
        "\n",
        "    \n",
        "    \n",
        "    return(total_loss/count, acc/len(val_loader.dataset))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KQKId9WIjW5",
        "outputId": "eb9170c4-19a7-4804-cfb6-d43f2a106cb8"
      },
      "source": [
        "avg_val_loss, val_accuracy = validate_model(model, val_loader)\n",
        "print(val_accuracy)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9922666666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkbq6FiJb-yW"
      },
      "source": [
        "torch.save(model.state_dict(), 'drive/MyDrive/605model_state_dict')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSPgIEEb1Q6a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmmx1Ot1K90Z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glAynHvW1Q87",
        "outputId": "2968639f-6cab-4fe0-e2ce-5f6e1b67492b"
      },
      "source": [
        "!wget http://millionsongdataset.com/sites/default/files/tasteprofile/sid_mismatches.txt\n",
        "!unzip drive/MyDrive/train_triplets.txt.zip\n",
        "!unzip drive/MyDrive/taste_profile_song_to_tracks.txt.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-01 05:49:30--  http://millionsongdataset.com/sites/default/files/tasteprofile/sid_mismatches.txt\n",
            "Resolving millionsongdataset.com (millionsongdataset.com)... 173.231.209.32\n",
            "Connecting to millionsongdataset.com (millionsongdataset.com)|173.231.209.32|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2026182 (1.9M) [text/plain]\n",
            "Saving to: ‘sid_mismatches.txt’\n",
            "\n",
            "sid_mismatches.txt  100%[===================>]   1.93M  3.25MB/s    in 0.6s    \n",
            "\n",
            "2020-12-01 05:49:31 (3.25 MB/s) - ‘sid_mismatches.txt’ saved [2026182/2026182]\n",
            "\n",
            "Archive:  drive/MyDrive/train_triplets.txt.zip\n",
            "  inflating: train_triplets.txt      \n",
            "Archive:  drive/MyDrive/taste_profile_song_to_tracks.txt.zip\n",
            "  inflating: taste_profile_song_to_tracks.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4Ikvqtk2UhR"
      },
      "source": [
        "songToTrackDf = pd.read_csv(\n",
        "    \"taste_profile_song_to_tracks.txt\", names=[\"song\", \"track\"], sep=\"\\t\")\n",
        "songToTrackDf.dropna(inplace=True)\n",
        "userSongCountDf = pd.read_csv(\n",
        "    \"train_triplets.txt\", names=[\"user\", \"song\", \"count\"], sep=\"\\t\")\n",
        "mismatches = []\n",
        "with open(\"sid_mismatches.txt\", \"r\", encoding='UTF-8') as f:\n",
        "    for line in f:\n",
        "        mismatches.append((line[8:8+len(songToTrackDf[\"song\"][0])], line[9+len(songToTrackDf[\"song\"][0]):9+len(songToTrackDf[\"song\"][0])+len(songToTrackDf[\"track\"][0])]))\n",
        "mismatchesDf = pd.DataFrame(mismatches, columns=[\"song\", \"track\"])\n",
        "songToTrackDf = songToTrackDf[(~songToTrackDf[\"track\"].isin(mismatchesDf[\"track\"])) & (~songToTrackDf[\"song\"].isin(mismatchesDf[\"song\"]))]\n",
        "userSongCountDf = userSongCountDf[userSongCountDf[\"song\"].isin(songToTrackDf[\"song\"])]\n",
        "userSongTrackCountDf = userSongCountDf.merge(songToTrackDf, how=\"left\", on=\"song\")\n",
        "userSongTrackCountDf = userSongTrackCountDf[userSongTrackCountDf[\"count\"] > 1]\n",
        "userSongTrackCountDf.reset_index(drop=True, inplace=True)\n",
        "uniqueSongs = userSongTrackCountDf[\"track\"].unique()\n",
        "tmp = userSongTrackCountDf[[\"user\", \"track\"]]\n",
        "\n",
        "userSongListDf = tmp.groupby(\"user\")[\"track\"].apply(list).reset_index(name='tracks')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yibXfQ162iYK"
      },
      "source": [
        "test = list(userSongListDf.iloc[-1]['tracks'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUVoIOAB3EEq"
      },
      "source": [
        "feature_subset = pickle.load(open('drive/MyDrive/parsed_subset.pkl', 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Unbi8x1q6G5a"
      },
      "source": [
        "feature_subset['track_id'] = feature_subset['track_id'].apply(lambda x: str(x[2:-1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDoUVdeU6Jth",
        "outputId": "1b651d22-8961-4777-e028-dc202c2082de"
      },
      "source": [
        "track_ids = feature_subset['track_id'].tolist()\n",
        "raw_track_ids = userSongTrackCountDf['track'].tolist()\n",
        "\n",
        "intersect_track_ids = set(raw_track_ids) & set(track_ids)\n",
        "print(len(intersect_track_ids))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpRYw44D6P2y",
        "outputId": "3fec27c9-e128-440c-b42f-a9b689432cca"
      },
      "source": [
        "print(len(userSongTrackCountDf))\n",
        "print(len(feature_subset['track_id']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18550228\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DF6u6yZY6Svc",
        "outputId": "ada128d3-b736-4a83-ccc8-8657de52079e"
      },
      "source": [
        "temp = userSongTrackCountDf[userSongTrackCountDf['track'].isin(feature_subset['track_id'])]\n",
        "print(len(temp))\n",
        "assert len(temp) == len(temp[temp['count'] > 1])\n",
        "temp = temp[[\"user\", \"track\"]]\n",
        "temp = temp.groupby(\"user\").filter(lambda x: len(x['track']) > 1)\n",
        "temp = temp.groupby(\"user\")[\"track\"].apply(list).reset_index(name='track_id')[[\"track_id\"]].to_numpy()\n",
        "temp = np.squeeze(temp)\n",
        "print(temp.shape)\n",
        "\n",
        "\n",
        "# sanity check that all remaining tracks are within intersected track_ids\n",
        "users_track_ids = set()\n",
        "for user_lst in temp:\n",
        "  users_track_ids.update(set(user_lst))\n",
        "assert len(users_track_ids - intersect_track_ids) == 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "237500\n",
            "(41346,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdZi_qgx6hM1"
      },
      "source": [
        "# compute pairs\n",
        "import itertools\n",
        "track_lsts = temp.tolist()\n",
        "\n",
        "pairs = set()\n",
        "for track_lst in track_lsts:\n",
        "  pairs.update(set(itertools.combinations(track_lst, 2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6m0Gnso-6_g3"
      },
      "source": [
        "# select features\n",
        "features = feature_subset[[\n",
        "    'track_id',\n",
        "    'artist_familiarity',\n",
        "    'danceability',\n",
        "    'duration',\n",
        "    'end_of_fade_in',\n",
        "    'key',\n",
        "    'key_confidence', \n",
        "    'loudness', \n",
        "    'mode',\n",
        "    'segments_confidence',\n",
        "    'segments_loudness_max',\n",
        "    'segments_loudness_max_time',\n",
        "    'segments_pitches',\n",
        "    'segments_timbre',\n",
        "    'tempo', \n",
        "    'time_signature', \n",
        "    'time_signature_confidence'\n",
        "]]\n",
        "features = features.set_index('track_id')\n",
        "\n",
        "# flatten 2d features segments_pitches and segments_timbre\n",
        "features['segments_pitches'] = features['segments_pitches'].apply(np.concatenate).apply(list)\n",
        "features['segments_timbre'] = features['segments_timbre'].apply(np.concatenate).apply(list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zm45KLPM7Bta"
      },
      "source": [
        "# flatten 2d features at column idx 8, 9, 10, 11, 12 corresponding to segments_...\n",
        "# new len should be 8 + 10 + 10 + 10 + 120 + 120 + 3 = 281\n",
        "def nested_flatten(lst):\n",
        "  nested_parts = lst[8] + lst[9] + lst[10] + lst[11] + lst[12]\n",
        "  return np.append(np.append(lst[:8], nested_parts), lst[13:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuuCVEFY7EWO"
      },
      "source": [
        "# map features to pairs to create datapoints, flatten in the meanwhile\n",
        "# datapoints stores (track1_id, track2_id): [(track1_id, track2_id), list_of_track1_features, list_of_track2_features]\n",
        "datapoints_d = {}\n",
        "for id1, id2 in pairs:\n",
        "  track1 = nested_flatten(features.loc[id1].to_numpy())\n",
        "  track2 = nested_flatten(features.loc[id2].to_numpy())\n",
        "  if id1 < id2: # bigger track_id always precede smaller track_id in pair positioning\n",
        "    track1, track2 = track2, track1\n",
        "    id1, id2 = id2, id1\n",
        "  datapoints_d[(id1, id2)] = [(id1, id2), track1, track2]\n",
        "\n",
        "# sanity check\n",
        "sample_point = list(datapoints_d.values())[1]\n",
        "sample_key = list(datapoints_d.keys())[1]\n",
        "assert len(sample_point) == 3\n",
        "assert sample_point[0] == sample_key\n",
        "assert len(sample_point[1]) == 281\n",
        "assert len(sample_point[2]) == 281"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6r2UGLR7IXY"
      },
      "source": [
        "# construct final data, where we have\n",
        "# features: track1_features & track2_features in a list\n",
        "# label: 1 if in datapoints_d, 0 if in negative_sample_datapoints\n",
        "data_features = []\n",
        "data_labels = []\n",
        "for p_data in datapoints_d.values():\n",
        "  track_id_pair, p_feature1, p_feature2 = p_data[0], p_data[1], p_data[2]\n",
        "  data_features.append(np.concatenate((p_feature1, p_feature2)))\n",
        "  data_labels.append(1)\n",
        "\n",
        "assert len(data_features) == len(data_labels)\n",
        "\n",
        "\n",
        "data_features = np.array(data_features)\n",
        "data_labels = np.array(data_labels)\n",
        "assert data_features.shape[0] == data_labels.shape[0]\n",
        "assert data_features.shape[1] == 281 * 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "yZn3EXoX7eXT",
        "outputId": "570dda2a-0828-42e0-bba8-dc22415751b3"
      },
      "source": [
        "datapoints_d.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-904c582623e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdatapoints_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fh9rZNFG7gNu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}